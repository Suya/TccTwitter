{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netebook para extrair features de menções\n",
    "## Nome: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "import csv\n",
    "\n",
    "#import utils\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import gc\n",
    "from pandas import read_csv\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calcular flesch_reading e ambiguidade\n",
    "\n",
    "from textstat.textstat import textstat\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "#textD=reviewFileDF['text'][:1].astype(str)\n",
    "\n",
    "\n",
    "class text_object(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word_count = 0\n",
    "        self.sentence_count = 0\n",
    "        self.syllable_count = 0\n",
    "        self.number_diff_words = 0 #to be calculated\n",
    "        self.avg_syllables_per_word = 0\n",
    "        self.avg_sentence_length = 0\n",
    "        #should frequency and top words be included?\n",
    "        \n",
    "    def print_metrics(self):\n",
    "        print \"word count =\"\n",
    "        print self.word_count\n",
    "    \n",
    "        print \"sentence count =\"\n",
    "        print self.sentence_count\n",
    "    \n",
    "        print \"syllable count =\"\n",
    "        print self.syllable_count\n",
    "    \n",
    "        print \"avg syllable per word =\"\n",
    "        print self.avg_syllables_per_word\n",
    "    \n",
    "        print \"avg sentence length =\"\n",
    "        print self.avg_sentence_length\n",
    "\n",
    "        \n",
    "def calc_basic_metrics (dataset, textObj):\n",
    "\n",
    "    numTweets = float(dataset.size /3)\n",
    "    wordTotal = 0\n",
    "    sentenceTotal = 0\n",
    "    syllableTotal = 0\n",
    "    avgSyllablesWord = 0\n",
    "    avgSentenceLength = 0\n",
    "    numberDiffWords = 0 #to be calculated\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        stat= row['text']\n",
    "        \n",
    "        wordTotal = wordTotal + word_count(stat)\n",
    "        sentenceTotal = sentenceTotal + sentence_count(stat)\n",
    "        syllableTotal = syllableTotal + syllable_count(stat)\n",
    "                \n",
    "        textObj.sentence_count = sentenceTotal / numTweets\n",
    "        textObj.word_count = wordTotal / numTweets\n",
    "        textObj.syllable_count = syllableTotal / numTweets\n",
    "        \n",
    "        #dataset['calc_coleman_liau_index'][index] = ret\n",
    "    \n",
    "    textObj.avg_syllables_per_word = syllableTotal/float(wordTotal)\n",
    "    textObj.avg_sentence_length = wordTotal/float(sentenceTotal)\n",
    "    \n",
    "    #dfTwitter.write_csv(\"/sdf/asdf/asd\")   \n",
    "        \n",
    "def preprocess_text(texto):\n",
    "    tokens = nltk.word_tokenize(texto.decode('utf-8'))\n",
    "    #check lenght words\n",
    "    words = [w.lower() for w in tokens if len(w)<20]\n",
    "    #print(words)   \n",
    "\n",
    "    #print(texto)   \n",
    "    #texto = nltk.Text(words)\n",
    "    return \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in words]).strip()  \n",
    "    \n",
    "def word_count (texto):\n",
    "    x=0\n",
    "    try:\n",
    "        x= textstat.lexicon_count(texto)\n",
    "    except:\n",
    "        x=0\n",
    "    return x\n",
    "\n",
    "def sentence_count (texto):\n",
    "    x=0\n",
    "    try:\n",
    "        x= textstat.sentence_count(texto)\n",
    "    except:\n",
    "        x=0\n",
    "    return x\n",
    "\n",
    "def syllable_count (texto):\n",
    "    x=0\n",
    "    try:\n",
    "        x= textstat.syllable_count(texto)\n",
    "    except:\n",
    "        x=0\n",
    "    return x\n",
    "\n",
    "def calc_flesch_reading_ease( text):\n",
    "\n",
    "    #text = preprocess_text(text)\n",
    "    x=0\n",
    "    try:\n",
    "        ASL = textstat.avg_sentence_length(text)\n",
    "        ASW = textstat.avg_syllables_per_word(text)\n",
    "\n",
    "        FRE = 206.835 - float(1.015 * ASL) - float(84.6 * ASW)\n",
    "        return round(FRE, 2)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calc_coleman_liau_index (texto):\n",
    "    x=0\n",
    "    try:\n",
    "        x= textstat.coleman_liau_index(texto)\n",
    "    except:\n",
    "        x=0\n",
    "    return x\n",
    "            \n",
    "def calc_flesch_kincaid_grade (texto):\n",
    "    x=0\n",
    "    try:\n",
    "        ASL = textstat.avg_sentence_length(texto)\n",
    "        ASW = textstat.avg_syllables_per_word(texto)\n",
    "        FKRA = float(0.39 * ASL) + float(11.8 * ASW) - 15.59\n",
    "        x= round(FKRA, 1)\n",
    "    except:\n",
    "        x=0\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def calcAmbiguidadte(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "    #check lenght words\n",
    "    tokens = [w.lower() for w in tokens if len(w)<20]\n",
    "    \n",
    "    #stopwordremoval\n",
    "    #stop = stopwords.words('english')\n",
    "    #tokens = [w.lower() for w in tokens if w not in stop]\n",
    "    \n",
    "    postag= nltk.pos_tag(tokens)\n",
    "\n",
    "\n",
    "    nVerb=0\n",
    "    nNoun=0\n",
    "    nAdjective=0\n",
    "    nAdverb=0\n",
    "\n",
    "    mVerb=0\n",
    "    mNoun=0\n",
    "    mAdjective=0\n",
    "    mAdverb=0\n",
    "\n",
    "    avgMVerb = 0\n",
    "    avgMNoun = 0\n",
    "    avgMAdjective = 0\n",
    "    avgMAdverb = 0\n",
    "\n",
    "    AvgAmbiquity = 0\n",
    "\n",
    "\n",
    "    #Tag Meaning\n",
    "    #https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "    for tag in postag:\n",
    "        word = tag[0]\n",
    "        word_clas = tag[1]\n",
    "        #print(word_clas)\n",
    "        if word_clas == \"VB\" or word_clas == \"VBD\" or word_clas == \"VBG\" or word_clas == \"VBN\" or word_clas == \"VBP\" or word_clas == \"VBZ\" :\n",
    "            nVerb +=1\n",
    "            mVerb += len(wn.synsets(word))\n",
    "        elif word_clas == \"NN\" or word_clas == \"NNS\" or word_clas == \"NNP\" or word_clas == \"NNPS\" :\n",
    "            nNoun +=1\n",
    "            mNoun += len(wn.synsets(word))\n",
    "        elif word_clas == \"JJ\" or word_clas == \"JJR\" or word_clas == \"JJS\" :\n",
    "            nAdjective +=1\n",
    "            mAdjective += len(wn.synsets(word))\n",
    "        elif word_clas == \"RB\" or word_clas == \"RBR\" or word_clas == \"RBS\":\n",
    "            nAdverb +=1\n",
    "            mAdverb += len(wn.synsets(word))\n",
    "\n",
    "\n",
    "    if nVerb > 0: avgMVerb =  mVerb / float(nVerb)\n",
    "    if nNoun > 0: avgMNoun = mNoun / float(nNoun)\n",
    "    if nAdjective > 0: avgMAdjective = mAdjective / float(nAdjective)\n",
    "    if nAdverb > 0: avgMAdverb = mAdverb / float(nAdverb)\n",
    "\n",
    "    if (nVerb+nNoun+nAdjective+nAdverb) > 0: AvgAmbiquity = (mVerb+mNoun+mAdjective+mAdverb) / float(nVerb+nNoun+nAdjective+nAdverb)\n",
    "    return AvgAmbiquity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1568627450980395"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcAmbiguidadte(\"The original Latin word universitas refers in general to a number of persons associated into one body, a society, company, community, guild, corporation, etc. At the time of the emergence of urban town life and medieval guilds, specialised associations of students and teachers with collective legal rights usually guaranteed by charters issued by princes, prelates, or the towns in which they were located came to be denominated by this general term. Like other guilds, they were self-regulating and determined the qualifications of their members.\")\n",
    "#calcAmbiguidadte(\"Life hack: drink 13 Pumpkin Spice Lattes in a row, and your bathroom will smell just like fall! Got caught smoking a hookah. Damn Armenian paparazzi! #ConanArmenia http://t.co/ochCoX700D Celebrating my assistant Sona's birthday in her homeland of Armenia. http://t.co/ofwfFWdQC5 #ConanArmenia Brought my assistant Sona home to Armenia. It was this or give her a raise. #ConanArmenia airs 11/10. http://t.co/m4beg84uHV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count =\n",
      "15.2129750983\n",
      "sentence count =\n",
      "1.16120576671\n",
      "syllable count =\n",
      "24.3630406291\n",
      "avg syllable per word =\n",
      "1.60146457032\n",
      "avg sentence length =\n",
      "13.1010158014\n",
      "\n",
      "word count =\n",
      "17.657540395\n",
      "sentence count =\n",
      "1.5\n",
      "syllable count =\n",
      "24.3613105925\n",
      "avg syllable per word =\n",
      "1.37965481304\n",
      "avg sentence length =\n",
      "11.7716935966\n",
      "\n",
      "word count =\n",
      "14.5006265664\n",
      "sentence count =\n",
      "1.31798245614\n",
      "syllable count =\n",
      "20.3609022556\n",
      "avg syllable per word =\n",
      "1.40413948062\n",
      "avg sentence length =\n",
      "11.0021392917\n"
     ]
    }
   ],
   "source": [
    "dfSuya = pd.read_csv(\"suyapc_tweets.csv\", encoding='utf-8')\n",
    "dfConan = pd.read_csv(\"ConanObrien_tweets.csv\", encoding='utf-8')\n",
    "dfGod = pd.read_csv(\"TheTweetOfGod_tweets.csv\", encoding='utf-8')\n",
    "\n",
    "\n",
    "textObj1 = text_object()\n",
    "textObj2 = text_object()\n",
    "textObj3 = text_object()\n",
    "\n",
    "\n",
    "calc_basic_metrics(dfSuya, textObj1)\n",
    "textObj1.print_metrics()\n",
    "print \"\"\n",
    "calc_basic_metrics(dfConan, textObj2)\n",
    "textObj2.print_metrics()\n",
    "print \"\"\n",
    "calc_basic_metrics(dfGod, textObj3)\n",
    "textObj3.print_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
